\contentsline {deleted}{Deleted: \truncate {\Changestruncatewidth }{on 2D projection of normal bundle embedding}}{4}{section*.5}%
\contentsline {added}{Added: \truncate {\Changestruncatewidth }{Obtaining the backbone.}}{4}{section*.7}%
\contentsline {deleted}{Deleted: \truncate {\Changestruncatewidth }{We obtain the core curve of the coil by applying a Gaussian filter to the backbone 3D space curve.}}{4}{section*.8}%
\contentsline {added}{Added: \truncate {\Changestruncatewidth }{To obtain the backbone of the coil, we first smooth the embedded residue sequence to suppress the loops by using a Gaussian filter. Let $t$ be the residue number of the protein sequence and $\vec {\gamma [t]}$ denote the the residue sequence embedded in 3-dimensional Euclidean space, where each component $\gamma _x[t], \gamma _y[t], \gamma _z[t]$ is a discrete time series. Furthermore, let $g_{\sigma }$ be the Gaussian function with standard deviation $\sigma $ and mean $0$, i.e. \begin {equation} g_{\sigma }[t] = \frac {1}{\sqrt {2\pi }\sigma } e^{-t^2 / (2 \sigma ^2)}. \end {equation} We then sample $g_{\sigma }$ discretely at indices $t$ between $-4 \sigma $ and $4 \sigma $, and we compute the smoothed sequence $\gamma _{i \sigma }$ for the $i^{\text {th}}$ component as the discrete convolution $\gamma _i * g_{\sigma }$, where $*$ denotes the discrete convolution operator; i.e. the convolution $f*g$ of two discrete functions $f$ and $g$ is given by \begin {equation} (f*g)[t] = \DOTSB \sum@ \slimits@ _{j=-\infty }^{\infty } f[t]g[t-j]. \end {equation} For the core curve, we compute $\vec {\gamma _{20}}[t] = (\gamma _{x20}[t], \gamma _{y20}[t], \gamma _{z20}[t])$.}}{5}{section*.9}%
\contentsline {added}{Added: \truncate {\Changestruncatewidth }{Tangent computation.}}{5}{section*.10}%
\contentsline {deleted}{Deleted: \truncate {\Changestruncatewidth }{We then compute the tangent vector field of the core curve via a Gaussian derivative, i.e. applying a derivative Gaussian filter by convolving each component $\gamma (t)$ of the core curve}}{5}{section*.11}%
\contentsline {added}{Added: \truncate {\Changestruncatewidth }{We now compute the tangent bundle $\vec {\gamma '_{\sigma }[t]}$ by computing component-wise derivatives of the original backbone $\vec {\gamma [t]}$. To numerically compute derivatives on such discrete data, we convolve each of them with the {\em derivative} of a Gaussian, $g'_{\sigma [t]}$, to obtain the derivatives $\gamma '_{i \sigma }$, where $g'_{\sigma [t]}$ is}}{5}{section*.12}%
\contentsline {added}{Added: \truncate {\Changestruncatewidth }{$g_{\sigma }$}}{5}{section*.13}%
\contentsline {deleted}{Deleted: \truncate {\Changestruncatewidth }{of the Gaussian \added {$g_{\sigma }$} via the formula $\gamma * g'_{\sigma }$ (in our case $\sigma = 1$)}}{5}{section*.14}%
\contentsline {added}{Added: \truncate {\Changestruncatewidth }{where, in practice, we use $\sigma =1$ to compute $\vec {\gamma '_{1}}$. By associativity of convolution and the derivative, this way of computing $\gamma '_{i \sigma }$ is equivalent to computing the derivative of $\gamma _{i \sigma }$ smoothed once more by $\gamma * g'_{\sigma }$. Such a smoothed derivative is a standard trick \cite {mokhtarian1992theory} for computing numerically meaningful derivatives of discrete time series which, from a naive continuous point of view, consist of a bunch of step functions with zero derivative everywhere except at the boundaries between time indices, where the derivative is undefined. }}{5}{section*.15}%
\contentsline {added}{Added: \truncate {\Changestruncatewidth }{\textbf {Normal computation and orthonormal framing.} Once we have the components of the tangent vector at each residue, we obtain the normal bundle}}{5}{section*.16}%
\contentsline {deleted}{Deleted: \truncate {\Changestruncatewidth }{The normal bundle is obtained}}{5}{section*.17}%
\contentsline {added}{Added: \truncate {\Changestruncatewidth }{once again}}{6}{section*.18}%
\contentsline {deleted}{Deleted: \truncate {\Changestruncatewidth }{and integral with cumulative sum}}{6}{section*.19}%
\contentsline {added}{Added: \truncate {\Changestruncatewidth }{, followed by a cumulative sum to approximate the integral in a discrete setting}}{6}{section*.20}%
\contentsline {added}{Added: \truncate {\Changestruncatewidth }{\textbf {Region identification.}}}{6}{section*.21}%
\contentsline {added}{Added: \truncate {\Changestruncatewidth }{(9 out of 127)}}{6}{section*.24}%
\contentsline {added}{Added: \truncate {\Changestruncatewidth }{, thereby necessitating a piecewise linear regression with more pieces}}{7}{section*.25}%
\contentsline {added}{Added: \truncate {\Changestruncatewidth }{We detect such anomalous structures by computing the standard deviation of the residuals vector for the sloped section of the 2-breakpoint regression. A large residual standard deviation indicates a break in sloping of the winding number and thus a low-confidence, non-coiling region in the protein structure. }}{7}{section*.26}%
\contentsline {deleted}{Deleted: \truncate {\Changestruncatewidth }{Eigenvectors of graph Laplacian on mutual nearest neighbors yield solenoid phase estimation}}{7}{section*.29}%
\contentsline {added}{Added: \truncate {\Changestruncatewidth }{Solenoid phase estimation}}{7}{section*.30}%
\contentsline {added}{Added: \truncate {\Changestruncatewidth }{, just as we did with the region annotation}}{7}{section*.31}%
\contentsline {added}{Added: \truncate {\Changestruncatewidth }{each component of }}{7}{section*.32}%
\contentsline {deleted}{Deleted: \truncate {\Changestruncatewidth }{, using the formula}}{7}{section*.33}%
\contentsline {added}{Added: \truncate {\Changestruncatewidth }{The formula for such a sliding window embedding of some sequence $f[t]$ is}}{8}{section*.34}%
\contentsline {deleted}{Deleted: \truncate {\Changestruncatewidth }{applied to each of the 3 components of the tangent vector field}}{8}{section*.35}%
\contentsline {added}{Added: \truncate {\Changestruncatewidth }{We concatenate together $\SW ^{24}_1 \gamma '_{i \sigma }$ for each of the three components of the tangent vector $\gamma '_{i \sigma }$}}{8}{section*.36}%
\contentsline {deleted}{Deleted: \truncate {\Changestruncatewidth }{ curve }}{8}{section*.37}%
\contentsline {added}{Added: \truncate {\Changestruncatewidth }{sequence}}{8}{section*.38}%
\contentsline {added}{Added: \truncate {\Changestruncatewidth }{Intuitively, the graph Laplacian is a generalization of a discrete second derivative operator to graphs. For the same reason that sines and cosines are eigenfunctions of the second derivative operator with associated eigenvalues proportional to the frequency, eigenvectors of the graph Laplacian on a graph of a circle are sine/cosine pairs, up to a phase, that go through an integer number of cycles over one revolution of the circle, and lower frequency pairs have smaller eigenvalues \cite {godsil2001algebraic}. We expect a near circular graph in the mutual-NN graph in the periodic LRR region, and the Laplacian eigenvectors are known to degrade gracefully in the presence of imperfections. Therefore, we expect the two eigenvectors with the smallest eigenvalue to be approximately periodic and $\pi /4$-phase shifted. If we use the two entries of these eigenvectors as \emph {x} and \emph {y} coordinates, respectively, we obtain a projection of the LRR coil onto a circle winding in the plane. Our phase estimation $\theta $ along the LRR coil is simply obtained as $\theta = \tan ^{-1}(\frac {y}{x})$, as shown in Figure \ref {fig:graphlap} below.}}{9}{section*.39}%
\contentsline {added}{Added: \truncate {\Changestruncatewidth }{We note that a similar phase-estimation scheme with the graph Laplacian of mutual nearest neighbors has been used to order photographs along a loop \cite {averbuch2015ringit} and to parameterize periodic videos \cite {tralie2018topological}. Furthermore, a spiritually similar but more computationally intensive topological phase estimation based on cohomology \cite {de2009persistent, perea2020sparse} has been applied to motion capture data \cite {vejdemo2015cohomological} and to recovering phase based on head orientation from neural data\cite {rybakken2019decoding}.}}{9}{section*.40}%
\contentsline {deleted}{Deleted: \truncate {\Changestruncatewidth }{Generically, the leading pair of 0\relax \textsuperscript {th} and 1\relax \textsuperscript {st} eigenvectors of the graph Laplacian are out-of-phase periodic functions with frequency matching the expected frequency of the LRR coil (Figure \ref {fig:graphlap}), and thus yield projection onto principal axes perpendicular to the core of the coil (Figure \ref {fig:graphlap}). Given these \emph {x} and \emph {y} coordinates, we compute phase estimation $\theta $ to obtain a phase estimation along the LRR coil as shown in Figure \ref {fig:graphlap} below.}}{9}{section*.42}%
\contentsline {added}{Added: \truncate {\Changestruncatewidth }{ The use of geometric and topological concepts in our method aligns with previous studies that have explored Topological Data Analysis (TDA) in protein structure and dynamics \cite {tang2022topological, cang2017topologynet}. For instance, SINATRA Pro has been used to identify biophysical signatures in protein dynamics by detecting topological differences between protein structures \cite {tang2022topological}. Similarly, TopologyNet integrates TDA with deep learning for biomolecular property predictions \cite {cang2017topologynet}. Our approach builds on these foundational ideas by leveraging large-scale AI/ML-derived databases like AlphaFoldDB, showcasing the potential of combining AI-based structural predictions with geometric and topological analyses for advanced domain annotation. }}{14}{section*.50}%
\contentsline {added}{Added: \truncate {\Changestruncatewidth }{Our method does come with limitations. For instance, while it can detect non-coiling structural anomalies within the LRR domain, the origin, authenticity, and potential functionality of these regions remain ambiguous. Moreover, our structure-based annotation method, albeit effective for domains with a straightforward geometric description like LRRs, might not be universally applicable to other protein domains without developing a new geometric model tailored to them. This underscores a potential limitation when juxtaposing sequence-based versus structure-based domain annotation, highlighting a future avenue warranting exploration: developing geometric models for other protein domains.}}{15}{section*.51}%
